
\newglossaryentry{MLg}
{
	name=Machine Learning,
	description={deutsch Maschinelles lernen. Ein künstliches System lernt aus Beispielen und kann diese nach Beendigung der Lernphase verallgemeinern. }
}

\newglossaryentry{XAI}
{
	name=Explainable artificial intelligence,
	description={deutsch erklärbare künstliche Inteligenz, Methodiken um Menschen die Vorhersagen durch Modelle des maschinellen Lernens zu erläutern. }
}

\newglossaryentry{DNN}
{
    name=Deep Neural Network,
    description={deutsch tiefes lernen, Bezeichnet Neuronale Netze mit vielen Zwischenschichten.}
}

\newglossaryentry{LRP}                                 
{
	name=Layer-wise Relevance Propagation,
	description={Technik zur Bestimmung der Merkmale welche am stärksten für das Endresultat verantwortlich sind.}                                   
}                             

\newglossaryentry{Black Box}                                 
{
	name=Black Box,
	description={System welches nicht im Quellcode vorhanden ist und dadurch nicht durch Analyse der Programmierung verstanden werden kann. Jegliche Rückschlüsse sind nur durch Beobachtungen möglich}                                   
}     

\newglossaryentry{DT}                                 
{
	name=Decision Tree,
	description={Entscheidungsbaum, Familie von ML Algorithmen}                                   
}     

\newglossaryentry{Grad CAM}
{
	name=Grad CAM,
	description={Gradient-weighted Class Activation Mapping, Technik welche für eine Entscheidung relevanten Bildinhalte optisch hervorhebt}  
}

\newglossaryentry{limeG}
{
	name=LIME,
	description={Local interpretable model-agnostic explanations, eine unabhängig des verwendeten Algorithmus anwendbare Erklärungstechnik für Black Box Modelle }
}

\newglossaryentry{tcavG}
{
	name=Testing with Concept Activation Vectors,
	description={Technik welche Erklärungen einer Klassifikation durch Erkennung der Bildbestandteile erzeugt. Benutzt dafür Neuronale Netze welche auf einzelnen Bestandteile trainiert werden. \parencite{Kim2017}}
}

\newglossaryentry{av}
{
	name=Activation Vector (Aktivierungsvektor),
	description={In einem Neuronalen Netzwerk erzeugt ein Neuron für jedes Bild welches Analysiert wird einen bestimmten Ausgangswert. Für mehrere Bilder bilden die jeweiligen Ausgangswerte des Neurons den sogenannten Aktivierungsvektor.}
}

\newglossaryentry{svccaG}
{
	name=SVCCA,
     description={Singular Vector Canonical Correlation Analysis, ein Verfahren welches Aktivierungs Vektoren eines Neuronalen Netzes vergleicht. Der Vergleich kann entweder zwischen den Layern eines Netzes oder zwischen unterschiedlichen Netzen durchgeführt werden. \parencite{Raghu2017}}
}

\newacronym{ML}{ML}{Machine Learning}

\newacronym{cnn}{CNN}{Convolutional Neural Network}

\newacronym{dnn}{DNN}{Deep Neural Network}

\newacronym{lrp}{LRP}{Layer-wise Relevance Propagation}

\newacronym{lime}{LIME}{Local interpretable model-agnostic explanations}

\newacronym{tcav}{TCAV}{Testing with Concept Activation Vectors}

\newacronym{svcca}{SVCCA}{Singular Vector Canonical Correlation Analysis}

\newacronym{xai}{XAI}{Explainable artificial intelligence}

\newacronym{glm}{GLM}{Generalized Linear Models}

\newacronym{gam}{GAM}{Generalized Additive Models}

\newacronym{lfr}{LFR}{Learned fair representations}

\newacronym{m-gbm}{M-GBM}{Monotonic gradient boosting}

\newacronym{pate}{PATE}{Private aggregation of teacher ensembles}

\newacronym{sbrl}{SBRL}{Scalable Bayesian rule list}

\newacronym{slim}{SLIM}{Supersparse linear integer models}

\newacronym{dek}{DEK}{Datenethikkommission}
