
\newglossaryentry{MLg}
{
	name=Machine Learning,
	description={deutsch Maschinelles lernen. Ein künstliches System lernt aus Beispielen und kann diese nach Beendigung der Lernphase verallgemeinern. }
}

\newglossaryentry{AIg}
{
	name=Artificial Intelligence,
	description={deutsch Künstliche Intelligenz. Nicht scharf abzugrenzender Bereich des Machine Learning in dem versucht wird ein intelligentes Verhalten
	 analog menschlicher oder tierischer Verhaltensweisen nachzubilden. }
}

\newglossaryentry{XAI}
{
	name=Explainable Artificial Intelligence,
	description={deutsch erklärbare künstliche Inteligenz, Methodiken um Menschen die Vorhersagen durch Modelle des maschinellen Lernens zu erläutern. }
}

\newglossaryentry{DNN}
{
    name=Deep Neural Network,
    description={deutsch tiefes lernen, Bezeichnet Neuronale Netze mit vielen Zwischenschichten.}
}

\newglossaryentry{NN}                                 
{
	name=Neuronales Netz,
	description={}   
}   

\newglossaryentry{LRP}                                 
{
	name=Layer-wise Relevance Propagation,
	description={Technik zur Bestimmung der Merkmale welche am stärksten für das Endresultat verantwortlich sind.}                                   
}                          

\newglossaryentry{Black Box}                                 
{
	name=Black Box,
	description={System welches nicht im Quellcode vorhanden ist und dadurch nicht durch Analyse der Programmierung verstanden werden kann. Jegliche Rückschlüsse sind nur durch Beobachtungen möglich}                                   
}     

\newglossaryentry{DT}                                 
{
	name=Decision Tree,
	description={Entscheidungsbaum, Familie von ML Algorithmen}                                   
}     

\newglossaryentry{GC}
{
	name=Grad CAM,
	description={Gradient-weighted Class Activation Mapping, Technik welche für eine Entscheidung relevanten Bildinhalte optisch hervorhebt}  
}

\newglossaryentry{KH}
{
	name=Kluger-Hans-Effekt,
	description={``Kluger Hans'' war ein Pferd aus dem Anfang des 20. Jahrhunderts das angeblich rechnen und zählen konnte, jedoch auf  die feinen Nuancen der Mimik und Körpersprache des Fragestellers reagierte. Seitdem wird als ``Kluger-Hans-Effekt'' eine unbewusste beeinflussung des Studienobjektes bezeichnet. In Machine Learning Lösungen kann der ``Kluger-Hans-Effekt'' auftauchen wenn ein Model mit Daten traniert wird welche die Vorhersage unbewusst in eine bestimmte Richtung lenken.}  
}

\newglossaryentry{OS}
{
	name=Occlusion Sensitivity,
	description={Verfahren um die für eine Klassifikation relevanten Bildinhalte zu finden indem bestimmte Bildinhalte entfernt werden (Occlusion) und die dabei entstehende Veränderung auf die Klassifikation gemessen wird.}  
}

\newglossaryentry{GI}
{
	name=Gradients Input,
	description={}  
}

\newglossaryentry{BIAS}
{
	name=Bias,
	description={Bias, deutsch Tendenz oder Voreingenommenheit, kann in Machine Learning Modellen auftreten wenn die Trainingsdaten unausgewogen sind. Dies kann zu einer sogenannten selbsterfüllenden Prophezeiung werden indem die Resultate des Models zu neuen Trainingsdatensätzen führen welche die Tendenz noch verstärken.}  
}

\newglossaryentry{limeG}
{
	name=LIME,
	description={Local interpretable model-agnostic explanations, eine unabhängig des verwendeten Algorithmus anwendbare Erklärungstechnik für Black Box Modelle }
}

\newglossaryentry{tcavG}
{
	name=Testing with Concept Activation Vectors,
	description={Technik welche Erklärungen einer Klassifikation durch Erkennung der Bildbestandteile erzeugt. Benutzt dafür Neuronale Netze welche auf einzelnen Bestandteile trainiert werden. \parencite{Kim2017}}
}

\newglossaryentry{av}
{
	name=Activation Vector (Aktivierungsvektor),
	description={In einem Neuronalen Netzwerk erzeugt ein Neuron für jedes Bild welches Analysiert wird einen bestimmten Ausgangswert. Für mehrere Bilder bilden die jeweiligen Ausgangswerte des Neurons den sogenannten Aktivierungsvektor.}
}

\newglossaryentry{svccaG}
{
	name=SVCCA,
     description={Singular Vector Canonical Correlation Analysis, ein Verfahren welches Aktivierungs Vektoren eines Neuronalen Netzes vergleicht. Der Vergleich kann entweder zwischen den Layern eines Netzes oder zwischen unterschiedlichen Netzen durchgeführt werden. \parencite{Raghu2017}}
}

\newglossaryentry{binClassificator}
{
	name=Binärer Klassifikator,
     description={Ein binärer Klassifikator ist eine Sonderform eines Klassifikators welche nur eine Klasse kennt. Häufig sind das ja/nein Fragen zum Beispiel ``ist auf diesem Bild ein Tumor erkennbar?''.}
}

\newacronym{ML}{ML}{Machine Learning}

\newacronym{AI}{AI}{Artificial Intelligence}

\newacronym{cnn}{CNN}{Convolutional Neural Network}

\newacronym{dnn}{DNN}{Deep Neural Network}

\newacronym{lrp}{LRP}{Layer-wise Relevance Propagation}

\newacronym{lime}{LIME}{Local interpretable model-agnostic explanations}

\newacronym{tcav}{TCAV}{Testing with Concept Activation Vectors}

\newacronym{svcca}{SVCCA}{Singular Vector Canonical Correlation Analysis}

\newacronym{xai}{XAI}{Explainable artificial intelligence}

\newacronym{glm}{GLM}{Generalized Linear Models}

\newacronym{gam}{GAM}{Generalized Additive Models}

\newacronym{lfr}{LFR}{Learned fair representations}

\newacronym{m-gbm}{M-GBM}{Monotonic gradient boosting}

\newacronym{pate}{PATE}{Private aggregation of teacher ensembles}

\newacronym{sbrl}{SBRL}{Scalable Bayesian rule list}

\newacronym{slim}{SLIM}{Supersparse linear integer models}

\newacronym{dek}{DEK}{Datenethikkommission}

\newacronym{gradcam}{Grad CAM}{Gradient-weighted Class Activation Mapping}

\newacronym{aip}{AIP}{Adversarial Image Perturbations}
